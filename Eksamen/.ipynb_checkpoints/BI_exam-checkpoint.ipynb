{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI Exam May 2025: COVID-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created by Group 7 - Kamilla, Jeanette, Juvena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as sm\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set plot styles for better visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tools ready, the next step is to load the COVID-19 dataset into Python so we can start analyzing it.\n",
    "\n",
    "In this case, we’re working with a single dataset:\n",
    "\n",
    "- **OWID COVID-19 Latest Data**: a CSV file that contains country-level information on cases, deaths, vaccinations, testing, and various socioeconomic indicators.\n",
    "\n",
    "We'll use Pandas to read the CSV file and store it as a DataFrame. To make our code cleaner and reusable, we'll define a simple function that loads the data and performs some initial checks. This way, we can easily reload or replace the dataset if needed in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for the covid datasets. (dataset: last updated 2024-08-04)\n",
    "dataset_covid = 'Data/owid-covid-latest.csv'\n",
    "\n",
    "# Function to load the Excel files\n",
    "def load_csv_to_dataframe(file_path):\n",
    "    # Reads the Excel file and skips the first row if it contains a description or title\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Load datasets\n",
    "print(\"..Loading COVID-19 dataset\")\n",
    "df_covid = load_csv_to_dataframe(dataset_covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset, we want to explore it to understand what kind of information it contains and how it's structured.\n",
    "\n",
    "To do this, we can use several helpful Pandas functions such as `shape`, `types`, `info()`, `head()`, `tail()`, `sample()`, `describe()` and `isnull().sum()`. These functions will give us insights into the number of rows and columns, the data types of each column, a summary of the data, and any missing values. \n",
    "\n",
    "This exploration is crucial as it helps us identify potential issues or areas that need further cleaning or transformation before we proceed with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame (rows, columns)\n",
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the types of attributes (colum names) in the DataFrame\n",
    "df_covid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives an overview of the DataFrame\n",
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the DataFrame\n",
    "df_covid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of 5 rows from the DataFrame\n",
    "df_covid.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives summary statistics for all numerical columns in the dataset\n",
    "df_covid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1 Summary of exploring the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the dataframe, we found that it contains a large number of columns, many of which are not useful for our analysis or modeling goals. While some columns provide valuable information (like total cases, deaths, and vaccination rates), others are either redundant, mostly empty, or irrelevant.\n",
    "\n",
    "This highlights the need for a thorough data cleaning step to remove unnecessary columns, handle missing values, and focus only on the most relevant features for our machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and exploring the data, we need to clean it to ensure that our analysis is accurate and meaningful. Data cleaning involves several steps, including: checking for missing values, removing duplicates, and converting data types.\n",
    "\n",
    "We start by doing a bit of cleaning of the big dataset, to remove rows and columns that are not relevant for our futher analysis and before we seperate the data into more specific datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that many columns contain no values at all, so we will remove them to clean up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before cleaning the data, we want to remove irrelevant OWID aggregate rows—such as those representing high-income, low-income, and other income groupings.\n",
    "rows_to_remove = [\"OWID_UMC\", \"OWID_WRL\", \"OWID_LMC\", \"OWID_LIC\", \"OWID_HIC\"]\n",
    "df_removed_rows = df_covid[~df_covid[\"iso_code\"].isin(rows_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are removing the 'low-income countries', 'lower-middle-income countries', 'upper-middle-income countries', 'high-income countries' and 'world' categories because they are too broad and lack specific country-level detail, making it difficult to draw meaningful conclusions without relying on assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the above rows were removed\n",
    "print(f\"{df_covid.shape}\")\n",
    "print(f\"Removed the {df_covid.shape[0] - df_removed_rows.shape[0]} OWID rows from the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop all columns with no values at all like; excess_mortality_cumulative_absolute, excess_mortality_cumulative etc.\n",
    "df_covid_removed_columns = df_removed_rows.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the columns were removed\n",
    "print(f\"COVID dataframe shape after removing columns: {df_covid_removed_columns.shape}\")\n",
    "print(f\"Removed {df_covid.shape[1] - df_covid_removed_columns.shape[1]} columns from the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Separating the data into different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate the continent-level , age-level and health-level data into their own DataFrames so that we can clean and process them independently from the country-level data. This allows us to apply different cleaning steps based on the nature of the data, since data may have different structures or missing values compared to individual countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1 Separating the continent-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter the DataFrame based on a list of values\n",
    "def filter_dataframe(df, values, filter_type='rows', row_filter_column=None):\n",
    "    if filter_type == 'rows':\n",
    "        if row_filter_column is None:\n",
    "            raise ValueError(\"Must specify 'row_filter_column' when filtering rows.\")\n",
    "        return df[df[row_filter_column].isin(values)]\n",
    "    elif filter_type == 'columns':\n",
    "        # Keep only columns present in df and in values list (avoid key error)\n",
    "        columns_to_keep = [col for col in values if col in df.columns]\n",
    "        return df[columns_to_keep]\n",
    "    else:\n",
    "        raise ValueError(\"filter_type must be either 'rows' or 'columns'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before removing the iso_code column, we want to secure the OWID fields for the continents since it could be relevant data to analyze.\n",
    "rows_to_secure = [\"OWID_AFR\", \"OWID_ASI\", \"OWID_EUR\", \"OWID_EUN\", \"OWID_NAM\", \"OWID_OCE\", \"OWID_SAM\"]\n",
    "df_continents = filter_dataframe(df_covid_removed_columns, rows_to_secure, filter_type='rows', row_filter_column='iso_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the rows were secured\n",
    "df_continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new seperate dataframe called `df_continent` that contains the continent-level data. This DataFrame will be used for further analysis and modeling, while the original `df_covid` DataFrame will focus on country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are irrelavnt since they contain no values at all like; population_density, median_age etc.\n",
    "df_continents_romved_columns = df_continents.dropna(axis=1, how='all')\n",
    "df_continents_romved_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `new_vaccinations_smoothed_per_million`, `new_people_vaccinated_smoothed` and `new_people_vaccinated_smoothed_per_hundred` contain a lot of missing values so they are not necessary for our analysis and we will drop them from the `df_continents_cleaned` DataFrame. By removing them, we can simplify the DataFrame and focus on the most relevant features for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the columns were removed\n",
    "print(f\"df_continent shape after removing columns: {df_continents_romved_columns.shape}\")\n",
    "print(f\"Removed {df_continents.shape[1] - df_continents_romved_columns.shape[1]} columns from the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns there are irrelevant \n",
    "df_continents_cleaned = df_continents_romved_columns.drop(['iso_code', 'new_vaccinations_smoothed_per_million', 'new_people_vaccinated_smoothed', 'new_people_vaccinated_smoothed_per_hundred'], axis=1)\n",
    "df_continents_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_continents_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some rows with missing values in the df_continents_cleaned DataFrame, so we will impute them to ensure that our analysis is accurate and meaningful. This step is important because missing values can lead to biased results or errors in our models.\n",
    "\n",
    "Since it is a small dataframe, we can't delete the row with missing values(NaN), since we will lose a lot of data. We choose to replace the missing values, even though it can have a high risk of giving wrong information and have a big impact. \n",
    "\n",
    "The first four we replaced using realistic data.\n",
    "But since it took too much time, we’ll use the median to fill the remaining NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for replacing cell with a value\n",
    "def replace_cell(df, row_filter, column, value):\n",
    "    df.loc[row_filter, column] = value\n",
    "\n",
    "# replace NaN for total_vaccinations for Africa. 1.084.500.000 is from Africa CDC, which is offical and reliable.\n",
    "replace_cell(df_continents_cleaned, df_continents_cleaned['location'] == 'Africa', 'total_vaccinations', 1084500000)\n",
    "\n",
    "# replace NaN for total_vaccinations for South America. 970.800.000 is from WTO-IMF COVID-19 Vaccine Trade Tracker, which is offical and reliable.\n",
    "replace_cell(df_continents_cleaned, df_continents_cleaned['location'] == 'South America', 'total_vaccinations', 970800000)\n",
    "\n",
    "# replace NaN for people_vaccinated for Africa. 725.000.000 is from Africa CDC, which is offical and reliable\n",
    "replace_cell(df_continents_cleaned, df_continents_cleaned['location'] == 'Africa', 'people_vaccinated', 725000000)\n",
    "\n",
    "# replace NaN for people_vaccinated for South America. 351.310.000 is from Our World in Data which is offical and reliable used by WHO.\n",
    "replace_cell(df_continents_cleaned, df_continents_cleaned['location'] == 'South America', 'people_vaccinated', 351310000)\n",
    "\n",
    "# method for replacing cell with median \n",
    "def fill_na_with_median(df, column_name):\n",
    "    median_value = df[column_name].median()\n",
    "    print(f\"Median of '{column_name}': {median_value:.2f}\")\n",
    "    df[column_name].fillna(median_value, inplace=True)\n",
    "\n",
    "\n",
    "fill_na_with_median(df_continents_cleaned, 'people_fully_vaccinated')\n",
    "fill_na_with_median(df_continents_cleaned, 'total_boosters')\n",
    "fill_na_with_median(df_continents_cleaned, 'new_vaccinations')\n",
    "fill_na_with_median(df_continents_cleaned, 'new_vaccinations_smoothed')\n",
    "fill_na_with_median(df_continents_cleaned, 'total_vaccinations_per_hundred')\n",
    "fill_na_with_median(df_continents_cleaned, 'people_vaccinated_per_hundred')\n",
    "fill_na_with_median(df_continents_cleaned, 'people_fully_vaccinated_per_hundred')\n",
    "fill_na_with_median(df_continents_cleaned, 'total_boosters_per_hundred')\n",
    "df_continents_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2 Separating the age-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the same function as above to seperate the age-level columns from the rest of the data.\n",
    "columns_to_secure = [\"continent\", \"location\", \"total_deaths_per_million\", \"median_age\", \"aged_65_older\", \"aged_70_older\", \"life_expectancy\"]\n",
    "df_age = filter_dataframe(df_covid_removed_columns, columns_to_secure, filter_type='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the rows were secured\n",
    "df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new seperate dataframe called `df_age` that contains the age-level data. This DataFrame will be used for further analysis and modeling, while the original `df_covid` DataFrame will focus on country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with NaN values in the 'median_age' column\n",
    "df_age_cleaned = df_age.dropna(subset=['median_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do another check for missing values in the DataFrame\n",
    "df_age_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some missing values in the `df_age_cleaned` DataFrame, so we will impute them to ensure that our analysis is accurate and meaningful. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with the median for the columns; total_deaths_per_million, aged_65_older and aged_70_older\n",
    "fill_na_with_median(df_age_cleaned, \"total_deaths_per_million\")\n",
    "fill_na_with_median(df_age_cleaned, \"aged_65_older\")\n",
    "fill_na_with_median(df_age_cleaned, \"aged_70_older\")\n",
    "df_age_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_age_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.3 Separating the health-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the same function as above to seperate the health-level columns from the rest of the data.\n",
    "columns_to_secure = [\"continent\", \"location\", \"total_deaths_per_million\", \"cardiovasc_death_rate\", \"diabetes_prevalence\", \"female_smokers\", \"male_smokers\", \"life_expectancy\"]\n",
    "df_health = filter_dataframe(df_covid_removed_columns, columns_to_secure, filter_type='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the rows were secured\n",
    "df_health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new seperate dataframe called `df_health` that contains age-level data. This DataFrame will be used for further analysis and modeling, while the original `df_covid` DataFrame will focus on country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_health.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with NaN values in the 'female_smokers' column\n",
    "df_health_cleaned = df_health.dropna(subset=['female_smokers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do another check for missing values in the DataFrame\n",
    "df_health_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some missing values in the `df_health_cleaned` DataFrame, so we will impute them to ensure that our analysis is accurate and meaningful. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with the median for the columns; cardiovasc_death_rate and male_smokers\n",
    "fill_na_with_median(df_health_cleaned, \"cardiovasc_death_rate\")\n",
    "fill_na_with_median(df_health_cleaned, \"male_smokers\")\n",
    "df_health_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_health_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Futher cleaning of the country-level data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected a subset of columns that we consider relevant for our analysis. This subset includes columns that provide information on total cases, deaths and population. By focusing on these columns, we can simplify our analysis and make it easier to draw meaningful conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a new dataframe with the columns we want to keep for future analysis.\n",
    "columns_we_want_to_keep = [\n",
    "    \"iso_code\", \"continent\", \"location\", \"total_cases\", \"total_deaths\",\n",
    "    \"total_cases_per_million\", \"total_deaths_per_million\",\n",
    "    \"life_expectancy\", \"population\"]\n",
    "\n",
    "# Removes all other columns\n",
    "df_covid = df_covid_removed_columns[columns_we_want_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the columns were removed\n",
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load another dataset so we can add data about the Human Development Index (HDI) for each country. The HDI is a composite index of life expectancy, education, and per capita income indicators, which are used to rank countries into four tiers of human development. This additional information will help us better understand the relationship between COVID-19 and various socioeconomic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the new dataset\n",
    "hdi = pd.read_csv('Data/human-development-index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we can then add a column with the HDI data for 2021 matching the countries in the covid dataset, because we only need data from the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter HDI for 2021 only\n",
    "hdi_2021 = hdi[hdi['Year'] == 2021]\n",
    "\n",
    "# Merge using 'location' from df_covid and 'Entity' from hdi\n",
    "df_merged = df_covid.merge(\n",
    "    hdi_2021[['Entity', 'Human Development Index']], \n",
    "    left_on='location', \n",
    "    right_on='Entity', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the extra 'Entity' column after merge, since we don't need it\n",
    "df_merged = df_merged.drop(columns=['Entity'])\n",
    "\n",
    "# Rename the column in the merged dataframe\n",
    "df_merged = df_merged.rename(columns={'Human Development Index': 'human_development_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the dataset look and how we should proceed\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataframe after some cleaning\n",
    "print(f\"COVID dataframe shape after removing both some columns and rows: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are isolating the remaining rows in the df_covid DataFrame to ensure it contains only country-level data. This allows us to clean the dataset and retain only the features that are most relevant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we seperated the OWID continent fields into it's own dataframe earlier, we now have to remove them again for the df_covid dataframe.\n",
    "rows_to_remove = [\"OWID_AFR\", \"OWID_ASI\", \"OWID_EUR\", \"OWID_EUN\", \"OWID_NAM\", \"OWID_OCE\", \"OWID_SAM\"]\n",
    "df_covid_removed_rows = df_merged[~df_merged['iso_code'].isin(rows_to_remove)]\n",
    "df_covid_cleaned = df_covid_removed_rows.dropna(subset=['iso_code'])\n",
    "df_covid_cleaned = df_covid_cleaned.drop(columns=['iso_code'])\n",
    "df_covid_cleaned        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the rows were removed\n",
    "print(f\"COVID dataframe shape after removing rows: {df_covid_cleaned.shape}\")\n",
    "print(f\"Removed {df_merged.shape[0] - df_covid_cleaned.shape[0]} rows from the dataframe.\")\n",
    "print(f\"Removed {df_merged.shape[1] - df_covid_cleaned.shape[1]} column from the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of missing values for the human_development_index column, so we will impute them with the HDI from the sovereign countries they belong too. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which locations have missing HDI values\n",
    "missing_hdi_locations = df_covid_cleaned[df_covid_cleaned['human_development_index'].isna()]\n",
    "print(missing_hdi_locations['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "territory_to_country = {\n",
    "    'American Samoa': 'United States',\n",
    "    'Anguilla': 'United Kingdom',\n",
    "    'Aruba': 'Netherlands',\n",
    "    'Bermuda': 'United Kingdom',\n",
    "    'Bonaire Sint Eustatius and Saba': 'Netherlands',\n",
    "    'British Virgin Islands': 'United Kingdom',\n",
    "    'Cayman Islands': 'United Kingdom',\n",
    "    'Cook Islands': 'New Zealand',\n",
    "    'Curacao': 'Netherlands',\n",
    "    'Falkland Islands': 'United Kingdom',\n",
    "    'Faroe Islands': 'Denmark',\n",
    "    'French Guiana': 'France',\n",
    "    'French Polynesia': 'France',\n",
    "    'Gibraltar': 'United Kingdom',\n",
    "    'Greenland': 'Denmark',\n",
    "    'Guadeloupe': 'France',\n",
    "    'Guam': 'United States',\n",
    "    'Guernsey': 'United Kingdom',\n",
    "    'Isle of Man': 'United Kingdom',\n",
    "    'Jersey': 'United Kingdom',\n",
    "    'Kosovo': 'Serbia',  # or leave as is if Kosovo has its own HDI\n",
    "    'Martinique': 'France',\n",
    "    'Mayotte': 'France',\n",
    "    'Monaco': 'France',\n",
    "    'Montserrat': 'United Kingdom',\n",
    "    'Nauru': 'Nauru',\n",
    "    'New Caledonia': 'France',\n",
    "    'Niue': 'New Zealand',\n",
    "    'North Korea': 'North Korea',\n",
    "    'Northern Mariana Islands': 'United States',\n",
    "    'Pitcairn': 'United Kingdom',\n",
    "    'Puerto Rico': 'United States',\n",
    "    'Reunion': 'France',\n",
    "    'Saint Barthelemy': 'France',\n",
    "    'Saint Helena': 'United Kingdom',\n",
    "    'Saint Martin (French part)': 'France',\n",
    "    'Saint Pierre and Miquelon': 'France',\n",
    "    'Sint Maarten (Dutch part)': 'Netherlands',\n",
    "    'Somalia': 'Somalia',\n",
    "    'Tokelau': 'New Zealand',\n",
    "    'Turks and Caicos Islands': 'United Kingdom',\n",
    "    'United States Virgin Islands': 'United States',\n",
    "    'Vatican': 'Italy',\n",
    "    'Wallis and Futuna': 'France'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the territory to its sovereign country:\n",
    "df_covid_cleaned['hdi_source_country'] = df_covid_cleaned['location'].map(territory_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup for HDI values of sovereign countries\n",
    "hdi_lookup = df_covid_cleaned.set_index('location')['human_development_index'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing HDI values with the sovereign country’s HDI\n",
    "df_covid_cleaned['human_development_index'] = df_covid_cleaned.apply(\n",
    "    lambda row: hdi_lookup.get(row['hdi_source_country'], row['human_development_index']) \n",
    "    if pd.isna(row['human_development_index']) else row['human_development_index'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_covid_cleaned.drop(columns=['hdi_source_country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which locations have missing HDI values\n",
    "missing_hdi_locations = df_covid_cleaned[df_covid_cleaned['human_development_index'].isna()]\n",
    "print(missing_hdi_locations['location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found data for the human_development_index for 2021 for Nauru and Somalia on the https://hdr.undp.org/ website. We will use this data to fill in the missing values for these two countries in our dataset. We weren't able to find data on the human_development_index for North Korea, so we will impute it with the median value of the HDI for the other countries in the dataset. \n",
    "\n",
    "We will also impute the missing values for the columns total_cases, total_deaths, total_cases_per_million, total_deaths_per_million and life_expectancy with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing HDI values for Nauru and Somalia and impute North Korea with median value\n",
    "replace_cell(df_covid_cleaned, df_covid_cleaned['location'] == 'Nauru', 'human_development_index', 0.692)\n",
    "replace_cell(df_covid_cleaned, df_covid_cleaned['location'] == 'Somalia', 'human_development_index', 0.385)\n",
    "fill_na_with_median(df_covid_cleaned, \"human_development_index\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_cases\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_deaths\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_cases_per_million\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_deaths_per_million\")\n",
    "fill_na_with_median(df_covid_cleaned, \"life_expectancy\")\n",
    "df_covid_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_covid_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hypotese 1: Higher population size is associated with higher total COVID-19 deaths, but not necessarily with higher deaths per capita. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4.1 Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame (rows, columns)\n",
    "df_covid_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives an overview of the DataFrame\n",
    "df_covid_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives summary statistics for all numerical columns in the dataset\n",
    "df_covid_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Check for outliers in the df_covid_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in covid dataset using IQR method\n",
    "print(\"\\n..Checking for outliers in the covid dataframe:\")\n",
    "\n",
    "# Loop through selected columns\n",
    "for column in ['population', 'total_deaths_per_million', 'total_deaths']:\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = df_covid_cleaned[column].quantile(0.25)\n",
    "    Q3 = df_covid_cleaned[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "\n",
    "    # Define the lower and upper bounds for detecting outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Find rows where the value is outside the normal range\n",
    "    outliers = df_covid_cleaned[\n",
    "        (df_covid_cleaned[column] < lower_bound) | \n",
    "        (df_covid_cleaned[column] > upper_bound)\n",
    "    ]\n",
    "\n",
    "    # Print the number of outliers found for the column\n",
    "    print(f\"  {column}: {len(outliers)} outliers detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the IQR method to find outliers in the dataset for population, total deaths, and deaths per million. Outliers are values that lie far outside the typical range. This helps us spot extreme countries that might skew the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion from outliers is\n",
    "We identified several outliers in the dataset, especially in the columns for population and total deaths. This indicates that some countries—such as the USA and India—have extreme values that differ significantly from the rest, supporting the hypothesis that larger populations are associated with higher total COVID-19 deaths.\n",
    "In contrast, outliers in deaths per capita—like Belgium and Hungary—show that smaller countries can have disproportionately high death rates. This confirms that while population size influences the total number of deaths, it does not necessarily lead to higher deaths per person. Identifying these outliers ensures more reliable and balanced conclusions in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated deaths per capita to better compare COVID-19 impact across countries with different population sizes. While total deaths show how many people died, deaths per capita reveal how severely each country was affected relative to its population. This helps us identify smaller countries with high death rates that total numbers alone might hide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total dødsfald\n",
    "df_covid_cleaned.boxplot(column='total_deaths_per_million')\n",
    "plt.title('Outliers i Total Deaths')\n",
    "plt.show()\n",
    "\n",
    "# Dødsfald pr. capita\n",
    "df_covid_cleaned.boxplot(column='total_deaths') \n",
    "plt.title('Outliers i total deaths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots show that total deaths have many extreme outliers, likely from large countries with high populations. In contrast, deaths per million have fewer and more moderate outliers, suggesting that while total deaths vary greatly, the death rate per person is more stable. This supports the hypothesis that population size is linked to total deaths but not necessarily to deaths per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total deaths vs population\n",
    "sns.scatterplot(data=df_covid_cleaned, x='population', y='total_deaths_per_million')\n",
    "plt.title('Population vs Total COVID-19 total deaths per million')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Total Deaths per million')\n",
    "plt.show()\n",
    "\n",
    "# Deaths per capita vs population\n",
    "sns.scatterplot(data=df_covid_cleaned, x='population', y='total_deaths')  \n",
    "plt.title('Population vs COVID-19 total deaths')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Total deaths')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplots show a clear positive trend between population size and total COVID-19 deaths, suggesting that countries with larger populations tend to report more deaths overall. In contrast, there is no clear pattern between population size and deaths per million, supporting the idea that higher population size does not necessarily lead to a higher death rate per person. This aligns with the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistics\n",
    "scaled_data = df_covid_cleaned[['total_deaths_per_million']]\n",
    "\n",
    "print('Mean:', scaled_data['total_deaths_per_million'].mean())\n",
    "print('Standard Deviation:', scaled_data['total_deaths_per_million'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw histogram to visualize them\n",
    "sns.histplot(scaled_data['total_deaths_per_million'], color='#ee4c2c', bins=50);\n",
    "plt.ylabel(\"Number of countries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This right-skewed distribution indicates that while some countries experienced extreme death rates, the majority had moderate impacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard Scalling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce all with the mean and scale the data to unit variance\n",
    "# x = (x-xmean)/std\n",
    "standard_scaler = StandardScaler()\n",
    "scaled_data['total_deaths_per_million'] = standard_scaler.fit_transform(scaled_data[['total_deaths_per_million']])\n",
    "\n",
    "print('Mean:', scaled_data['total_deaths_per_million'].mean()) # almost 0\n",
    "print('Standard Deviation:', scaled_data['total_deaths_per_million'].std()) # almost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram has same shape, but 0,0 is in the middle\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.histplot(scaled_data['total_deaths_per_million'], color='#ee4c2c', bins=50);\n",
    "plt.ylabel(\"Number of countries\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardized histogram shows that most countries have death rates per capita below the global average, with a few countries having significantly higher values. This confirms that while total deaths vary, high death rates per capita are limited to only a small number of countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Min-Max Scalling - Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "scaled_data['death_min_max_scaled'] = minmax_scaler.fit_transform(scaled_data[['total_deaths_per_million']])\n",
    "\n",
    "print('Mean:', scaled_data['death_min_max_scaled'].mean())\n",
    "print('Standard Deviation:', scaled_data['death_min_max_scaled'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values are in [0, 1]\n",
    "sns.histplot(scaled_data['death_min_max_scaled'], color='#ee4c2c', bins=50);\n",
    "plt.ylabel(\"Number of countries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying Min-Max scaling, the histogram confirms that most countries have low COVID-19 death rates per capita, with only a few outliers having significantly higher values. This supports the hypothesis that high per capita death rates are rare and concentrated in specific countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtrans = QuantileTransformer()\n",
    "scaled_data['death_trans_uniform'] = qtrans.fit_transform(scaled_data[['total_deaths_per_million']])\n",
    "\n",
    "print('Mean:', scaled_data['death_trans_uniform'].mean())\n",
    "print('Standard Deviation:', scaled_data['death_trans_uniform'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='continent', y='total_deaths_per_million', data=df_covid_cleaned)\n",
    "plt.title(\"Total deaths per capita by continent\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplot shows that Europe has the highest variation and median in COVID-19 deaths per capita, suggesting some European countries were hit especially hard. In contrast, Africa has the lowest values and least variation. This supports the idea that death rates per person differ significantly across continents, with small countries in Europe standing out as high outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vælg relevante kolonner\n",
    "corr_df = df_covid_cleaned[['population', 'total_deaths', 'total_deaths_per_million']]\n",
    "\n",
    "# Beregn korrelation\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population and total deaths have a moderate positive correlation (0.46).\n",
    "This supports your hypothesis, that says countries with larger populations tend to have more total COVID-19 deaths.\n",
    "Population and deaths per million have a very weak negative correlation (-0.07).\n",
    "This means population size is not meaningfully related to deaths per capita.\n",
    "Total deaths and deaths per million have a weak positive correlation (0.27).\n",
    "Suggests some connection, but not very strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression plot and correlation matrix support the hypothesis. There is a moderate positive correlation (0.46) between population size and total COVID-19 deaths, confirming that more populous countries tend to report more deaths. However, there is virtually no correlation (-0.069) between population and deaths per capita, indicating that population size does not predict the death rate per person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson helps quantify how strongly two numeric variables are linearly related, using a value between −1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation\n",
    "print(df_covid_cleaned[['population', 'total_deaths', 'total_deaths_per_million']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he results show a moderate positive correlation between population and total deaths (0.46), but almost no correlation between population and deaths per million (−0.07). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population vs Total Deaths\n",
    "sns.lmplot(data=df_covid_cleaned, x='population', y='total_deaths')\n",
    "plt.title('Regression: Population vs Total Deaths')\n",
    "plt.show()\n",
    "\n",
    "# Population vs Deaths per Capita\n",
    "sns.lmplot(data=df_covid_cleaned, x='population', y='total_deaths_per_million')\n",
    "plt.title('Regression: Population vs Deaths per million')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression plot shows a positive linear trend, meaning that as population size increases, total COVID-19 deaths also tend to rise. However, the points are widely scattered around the line, indicating that the relationship is not very strong. The weak slope and wide confidence interval reflect large variation between countries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4.2 Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent\n",
    "X = df_covid_cleaned['population'].values.reshape(-1, 1) # Uafhængig variabel\n",
    "# dependent\n",
    "y = df_covid_cleaned['total_deaths'].values.reshape(-1, 1) # Afhængig variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all\n",
    "plt.ylabel('total_deaths')\n",
    "plt.xlabel('population')\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent\n",
    "X = df_covid_cleaned['population'].values.reshape(-1, 1) # Uafhængig variabel\n",
    "# dependent\n",
    "y = df_covid_cleaned['total_deaths_per_million'].values.reshape(-1, 1) # Afhængig variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all\n",
    "plt.ylabel('total_deaths_per_million')\n",
    "plt.xlabel('population')\n",
    "plt.scatter(X, y, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned.plot.line(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='population',y='total_deaths',data=df_covid_cleaned,fit_reg=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='population',y='total_deaths_per_million',data=df_covid_cleaned,fit_reg=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion – Data Modelling\n",
    "\n",
    "The goal of this analysis was not to predict COVID-19 deaths, but to examine whether there is a statistical relationship between population size and total COVID-19 deaths. A linear regression between population and total deaths revealed a moderate positive relationship, supported by both regression plots and a correlation coefficient of approximately 0.46. Conversely, the correlation between population size and deaths per capita was nearly zero, suggesting no clear relationship. This supports the hypothesis that countries with larger populations tend to have more total deaths, but not necessarily higher deaths per capita. No predictive model was developed, as the purpose was to explore and understand relationships in the data – not to forecast future outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the subsets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a ML Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of Linear Regression model\n",
    "myreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit it to our data\n",
    "myreg.fit(X_train, y_train)\n",
    "myreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the calculated coefficients\n",
    "a = myreg.coef_\n",
    "b = myreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model is a line, y = a * x + b, or y = {a} * x + {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = myreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the Linear Regression \n",
    "plt.title('Linear Regression')\n",
    "plt.scatter(X, y, color='green')\n",
    "plt.plot(X_train, a*X_train + b, color='blue')\n",
    "plt.plot(X_test, y_predicted, color='orange')\n",
    "plt.xlabel('population')\n",
    "plt.ylabel('total_deaths_per_millio0n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a weak positive trend between population size and total deaths, there is almost no relationship between population and deaths per capita. This indicates that larger populations are associated with higher total deaths, but not necessarily higher deaths per person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict age from length\n",
    "death_predicted = myreg.predict([[170]])\n",
    "death_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_predict = a * 170 + b\n",
    "death_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mse = metrics.mean_squared_error(y_test, y_predicted)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate R-squared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance score: the proportion of the variance in a dependent variable that can be explained by the model\n",
    "# 1 for perfect prediction\n",
    "eV = round(explained_variance_score(y_test, y_predicted), 2)\n",
    "print('Explained variance score ',eV )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared: the proportion of the variation in the dependent variable that is predictable from the independent variable(s)\n",
    "from sklearn.metrics import r2_score\n",
    "#r2_score(y, predict(X))\n",
    "r2_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color='blue', label='Actual data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear regression')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Total Deaths')\n",
    "plt.title('Linear Regression: Population vs Total Deaths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression line between population and total deaths shows a very weak relationship, with an R-squared value of just 0.0049. This means population size alone explains less than 1% of the variation in total COVID-19 deaths across countries, suggesting that other factors play a much larger role.\n",
    "The model shows a very weak fit, with an R² of only 0.0049. This means population size explains less than 1% of the variation in total COVID-19 deaths across countries, suggesting that other factors have a much greater impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color='blue', label='Actual data')\n",
    "plt.plot(X, y_pred, color='red', label='Linear regression')\n",
    "plt.xlabel('Population')\n",
    "plt.ylabel('Total Deaths per million')\n",
    "plt.title('Linear Regression: Population vs Total Deaths per million')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression shows no meaningful relationship between population size and COVID-19 deaths per million. The nearly flat line indicates that population does not help predict how many people died per capita, supporting the hypothesis that larger populations are not linked to higher death rates per person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis supports the hypothesis that countries with larger populations tend to report higher total numbers of COVID-19 deaths, but not necessarily higher deaths per capita.\n",
    "\n",
    "Correlation and regression between population and total deaths show a moderate positive relationship, indicating that more populous countries generally experienced more deaths overall.\n",
    "\n",
    "In contrast, correlation and regression between population and deaths per million are weak to non-existent, suggesting that population size does not predict how severely a country was affected relative to its population.\n",
    "\n",
    "Visualizations, including scatterplots, boxplots, and regression lines, confirm that total deaths increase with population, while deaths per capita vary more independently.\n",
    "\n",
    "The low R² values in the regression models further confirm that population alone cannot explain much of the variation in death rates per person.\n",
    "\n",
    "Overall, the results support the hypothesis: population size is linked to the total number of deaths but not to the likelihood of death per individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hypotese 2: Countries with a higher Human Development Index (HDI) have experienced lower COVID-19 death rates per capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.1 Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Countries with a higher life expectancy and older populations (e.g. higher median age, % aged 65+, etc.) have experienced higher COVID-19 death rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6.1 Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Countries or continents with higher vaccination rates experienced lower COVID-19 death rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.1 Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
