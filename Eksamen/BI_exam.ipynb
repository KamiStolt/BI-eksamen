{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI Exam May 2025: COVID-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created by Group 7 - Kamilla, Jeanette, Juvena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as sm\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import preprocessing as prep\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "# Set plot styles for better visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tools ready, the next step is to load the COVID-19 dataset into Python so we can start analyzing it.\n",
    "\n",
    "In this case, we’re working with a single dataset:\n",
    "\n",
    "- **OWID COVID-19 Latest Data**: a CSV file that contains country-level information on cases, deaths, vaccinations, testing, and various socioeconomic indicators.\n",
    "\n",
    "We'll use Pandas to read the CSV file and store it as a DataFrame. To make our code cleaner and reusable, we'll define a simple function that loads the data and performs some initial checks. This way, we can easily reload or replace the dataset if needed in future steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for the covid datasets. (dataset: last updated 2024-08-04)\n",
    "dataset_covid = 'Data/owid-covid-latest.csv'\n",
    "\n",
    "# Function to load the Excel files\n",
    "def load_csv_to_dataframe(file_path):\n",
    "    # Reads the Excel file and skips the first row if it contains a description or title\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Load datasets\n",
    "print(\"..Loading COVID-19 dataset\")\n",
    "df_covid = load_csv_to_dataframe(dataset_covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset, we want to explore it to understand what kind of information it contains and how it's structured.\n",
    "\n",
    "To do this, we can use several helpful Pandas functions such as `shape`, `types`, `info()`, `head()`, `tail()`, `sample()`, `describe()` and `isnull().sum()`. These functions will give us insights into the number of rows and columns, the data types of each column, a summary of the data, and any missing values. \n",
    "\n",
    "This exploration is crucial as it helps us identify potential issues or areas that need further cleaning or transformation before we proceed with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame (rows, columns)\n",
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the types of attributes (colum names) in the DataFrame\n",
    "df_covid.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives an overview of the DataFrame\n",
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the DataFrame\n",
    "df_covid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random sample of 5 rows from the DataFrame\n",
    "df_covid.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives summary statistics for all numerical columns in the dataset\n",
    "df_covid.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.1 Summary of exploring the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring the dataframe, we found that it contains a large number of columns, many of which are not useful for our analysis or modeling goals. While some columns provide valuable information (like total cases, deaths, and vaccination rates), others are either redundant, mostly empty, or irrelevant.\n",
    "\n",
    "This highlights the need for a thorough data cleaning step to remove unnecessary columns, handle missing values, and focus only on the most relevant features for our machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and exploring the data, we need to clean it to ensure that our analysis is accurate and meaningful. Data cleaning involves several steps, including: checking for missing values, removing duplicates, and converting data types.\n",
    "\n",
    "We start by doing a bit of cleaning of the big dataset, to remove rows and columns that are not relevant for our futher analysis and before we seperate the data into more specific datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that many columns contain no values at all, so we will remove them to clean up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before cleaning the data, we want to remove irrelevant OWID aggregate rows—such as those representing high-income, low-income, and other income groupings.\n",
    "rows_to_remove = [\"OWID_UMC\", \"OWID_WRL\", \"OWID_LMC\", \"OWID_LIC\", \"OWID_HIC\"]\n",
    "df_removed_rows = df_covid[~df_covid[\"iso_code\"].isin(rows_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are removing the 'low-income countries', 'lower-middle-income countries', 'upper-middle-income countries', 'high-income countries' and 'world' categories because they are too broad and lack specific country-level detail, making it difficult to draw meaningful conclusions without relying on assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the above rows were removed\n",
    "print(f\"{df_covid.shape}\")\n",
    "print(f\"Removed the {df_covid.shape[0] - df_removed_rows.shape[0]} OWID rows from the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop all columns with no values at all like; excess_mortality_cumulative_absolute, excess_mortality_cumulative etc.\n",
    "df_covid_removed_columns = df_removed_rows.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the columns were removed\n",
    "print(f\"COVID dataframe shape after removing columns: {df_covid_removed_columns.shape}\")\n",
    "print(f\"Removed {df_covid.shape[1] - df_covid_removed_columns.shape[1]} columns from the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Separating the data into different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate the age-level and health-level data into their own DataFrames so that we can clean and process them independently from the country-level data. This allows us to apply different cleaning steps based on the nature of the data, since data may have different structures or missing values compared to individual countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1 Separating the age-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter the DataFrame based on a list of values\n",
    "def filter_dataframe(df, values, filter_type='rows', row_filter_column=None):\n",
    "    if filter_type == 'rows':\n",
    "        if row_filter_column is None:\n",
    "            raise ValueError(\"Must specify 'row_filter_column' when filtering rows.\")\n",
    "        return df[df[row_filter_column].isin(values)]\n",
    "    elif filter_type == 'columns':\n",
    "        # Keep only columns present in df and in values list (avoid key error)\n",
    "        columns_to_keep = [col for col in values if col in df.columns]\n",
    "        return df[columns_to_keep]\n",
    "    else:\n",
    "        raise ValueError(\"filter_type must be either 'rows' or 'columns'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the function above to seperate the age-level columns from the rest of the data.\n",
    "columns_to_secure = [\"continent\", \"location\", \"total_deaths_per_million\", \"median_age\", \"aged_65_older\", \"aged_70_older\", \"life_expectancy\"]\n",
    "df_age = filter_dataframe(df_covid_removed_columns, columns_to_secure, filter_type='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the rows were secured\n",
    "df_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new seperate dataframe called `df_age` that contains the age-level data. This DataFrame will be used for further analysis and modeling, while the original `df_covid` DataFrame will focus on country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_age.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with NaN values in the 'median_age' column\n",
    "df_age_cleaned = df_age.dropna(subset=['median_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do another check for missing values in the DataFrame\n",
    "df_age_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some missing values in the `df_age_cleaned` DataFrame, so we will impute them to ensure that our analysis is accurate and meaningful. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for replacing cell with median \n",
    "def fill_na_with_median(df, column_name):\n",
    "    median_value = df[column_name].median()\n",
    "    print(f\"Median of '{column_name}': {median_value:.2f}\")\n",
    "    df[column_name].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with the median for the columns; total_deaths_per_million, aged_65_older and aged_70_older\n",
    "fill_na_with_median(df_age_cleaned, \"total_deaths_per_million\")\n",
    "fill_na_with_median(df_age_cleaned, \"aged_65_older\")\n",
    "fill_na_with_median(df_age_cleaned, \"aged_70_older\")\n",
    "df_age_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_age_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2 Separating the health-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the same function as above to seperate the health-level columns from the rest of the data.\n",
    "columns_to_secure = [\"continent\", \"location\", \"total_deaths_per_million\", \"cardiovasc_death_rate\", \"diabetes_prevalence\", \"female_smokers\", \"male_smokers\", \"life_expectancy\"]\n",
    "df_health = filter_dataframe(df_covid_removed_columns, columns_to_secure, filter_type='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the rows were secured\n",
    "df_health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new seperate dataframe called `df_health` that contains health-level data. This DataFrame will be used for further analysis and modeling, while the original `df_covid` DataFrame will focus on country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_health.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the rows with NaN values in the 'female_smokers' column\n",
    "df_health_cleaned = df_health.dropna(subset=['female_smokers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do another check for missing values in the DataFrame\n",
    "df_health_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some missing values in the `df_health_cleaned` DataFrame, so we will impute them to ensure that our analysis is accurate and meaningful. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with the median for the columns; cardiovasc_death_rate and male_smokers\n",
    "fill_na_with_median(df_health_cleaned, \"cardiovasc_death_rate\")\n",
    "fill_na_with_median(df_health_cleaned, \"male_smokers\")\n",
    "df_health_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_health_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Futher cleaning of the country-level data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected a subset of columns that we consider relevant for our analysis. This subset includes columns that provide information on total cases, deaths and population. By focusing on these columns, we can simplify our analysis and make it easier to draw meaningful conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a new dataframe with the columns we want to keep for future analysis.\n",
    "columns_we_want_to_keep = [\n",
    "    \"iso_code\", \"continent\", \"location\", \"total_cases\", \"total_deaths\",\n",
    "    \"total_cases_per_million\", \"total_deaths_per_million\",\n",
    "    \"life_expectancy\", \"population\"]\n",
    "\n",
    "# Removes all other columns\n",
    "df_covid = df_covid_removed_columns[columns_we_want_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the columns were removed\n",
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load another dataset so we can add data about the Human Development Index (HDI) for each country. The HDI is a composite index of life expectancy, education, and per capita income indicators, which are used to rank countries into four tiers of human development. This additional information will help us better understand the relationship between COVID-19 and various socioeconomic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the new dataset\n",
    "hdi = pd.read_csv('Data/human-development-index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we can then add a column with the HDI data for 2021 matching the countries in the covid dataset, because we only need data from the last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter HDI for 2021 only\n",
    "hdi_2021 = hdi[hdi['Year'] == 2021]\n",
    "\n",
    "# Merge using 'location' from df_covid and 'Entity' from hdi\n",
    "df_merged = df_covid.merge(\n",
    "    hdi_2021[['Entity', 'Human Development Index']], \n",
    "    left_on='location', \n",
    "    right_on='Entity', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the extra 'Entity' column after merge, since we don't need it\n",
    "df_merged = df_merged.drop(columns=['Entity'])\n",
    "\n",
    "# Rename the column in the merged dataframe\n",
    "df_merged = df_merged.rename(columns={'Human Development Index': 'human_development_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the dataset look and how we should proceed\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataframe after some cleaning\n",
    "print(f\"COVID dataframe shape after removing both some columns and rows: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are isolating the remaining rows in the df_covid DataFrame to ensure it contains only country-level data. This allows us to clean the dataset and retain only the features that are most relevant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we seperated the OWID continent fields into it's own dataframe earlier, we now have to remove them again for the df_covid dataframe.\n",
    "rows_to_remove = [\"OWID_AFR\", \"OWID_ASI\", \"OWID_EUR\", \"OWID_EUN\", \"OWID_NAM\", \"OWID_OCE\", \"OWID_SAM\"]\n",
    "df_covid_removed_rows = df_merged[~df_merged['iso_code'].isin(rows_to_remove)]\n",
    "df_covid_cleaned = df_covid_removed_rows.dropna(subset=['iso_code'])\n",
    "df_covid_cleaned = df_covid_cleaned.drop(columns=['iso_code'])\n",
    "df_covid_cleaned        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the rows were removed\n",
    "print(f\"COVID dataframe shape after removing rows: {df_covid_cleaned.shape}\")\n",
    "print(f\"Removed {df_merged.shape[0] - df_covid_cleaned.shape[0]} rows from the dataframe.\")\n",
    "print(f\"Removed {df_merged.shape[1] - df_covid_cleaned.shape[1]} column from the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a lot of missing values for the human_development_index column, so we will impute them with the HDI from the sovereign countries they belong too. This step is important because missing values can lead to biased results or errors in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which locations have missing HDI values\n",
    "missing_hdi_locations = df_covid_cleaned[df_covid_cleaned['human_development_index'].isna()]\n",
    "print(missing_hdi_locations['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "territory_to_country = {\n",
    "    'American Samoa': 'United States',\n",
    "    'Anguilla': 'United Kingdom',\n",
    "    'Aruba': 'Netherlands',\n",
    "    'Bermuda': 'United Kingdom',\n",
    "    'Bonaire Sint Eustatius and Saba': 'Netherlands',\n",
    "    'British Virgin Islands': 'United Kingdom',\n",
    "    'Cayman Islands': 'United Kingdom',\n",
    "    'Cook Islands': 'New Zealand',\n",
    "    'Curacao': 'Netherlands',\n",
    "    'Falkland Islands': 'United Kingdom',\n",
    "    'Faroe Islands': 'Denmark',\n",
    "    'French Guiana': 'France',\n",
    "    'French Polynesia': 'France',\n",
    "    'Gibraltar': 'United Kingdom',\n",
    "    'Greenland': 'Denmark',\n",
    "    'Guadeloupe': 'France',\n",
    "    'Guam': 'United States',\n",
    "    'Guernsey': 'United Kingdom',\n",
    "    'Isle of Man': 'United Kingdom',\n",
    "    'Jersey': 'United Kingdom',\n",
    "    'Kosovo': 'Serbia',  # or leave as is if Kosovo has its own HDI\n",
    "    'Martinique': 'France',\n",
    "    'Mayotte': 'France',\n",
    "    'Monaco': 'France',\n",
    "    'Montserrat': 'United Kingdom',\n",
    "    'Nauru': 'Nauru',\n",
    "    'New Caledonia': 'France',\n",
    "    'Niue': 'New Zealand',\n",
    "    'North Korea': 'North Korea',\n",
    "    'Northern Mariana Islands': 'United States',\n",
    "    'Pitcairn': 'United Kingdom',\n",
    "    'Puerto Rico': 'United States',\n",
    "    'Reunion': 'France',\n",
    "    'Saint Barthelemy': 'France',\n",
    "    'Saint Helena': 'United Kingdom',\n",
    "    'Saint Martin (French part)': 'France',\n",
    "    'Saint Pierre and Miquelon': 'France',\n",
    "    'Sint Maarten (Dutch part)': 'Netherlands',\n",
    "    'Somalia': 'Somalia',\n",
    "    'Tokelau': 'New Zealand',\n",
    "    'Turks and Caicos Islands': 'United Kingdom',\n",
    "    'United States Virgin Islands': 'United States',\n",
    "    'Vatican': 'Italy',\n",
    "    'Wallis and Futuna': 'France'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the territory to its sovereign country:\n",
    "df_covid_cleaned['hdi_source_country'] = df_covid_cleaned['location'].map(territory_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup for HDI values of sovereign countries\n",
    "hdi_lookup = df_covid_cleaned.set_index('location')['human_development_index'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing HDI values with the sovereign country’s HDI\n",
    "df_covid_cleaned['human_development_index'] = df_covid_cleaned.apply(\n",
    "    lambda row: hdi_lookup.get(row['hdi_source_country'], row['human_development_index']) \n",
    "    if pd.isna(row['human_development_index']) else row['human_development_index'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_covid_cleaned.drop(columns=['hdi_source_country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which locations have missing HDI values\n",
    "missing_hdi_locations = df_covid_cleaned[df_covid_cleaned['human_development_index'].isna()]\n",
    "print(missing_hdi_locations['location'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found data for the human_development_index for 2021 for Nauru and Somalia on the https://hdr.undp.org/ website. We will use this data to fill in the missing values for these two countries in our dataset. We weren't able to find data on the human_development_index for North Korea, so we will impute it with the median value of the HDI for the other countries in the dataset. \n",
    "\n",
    "We will also impute the missing values for the columns total_cases, total_deaths, total_cases_per_million, total_deaths_per_million and life_expectancy with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for replacing cell with a value\n",
    "def replace_cell(df, row_filter, column, value):\n",
    "    df.loc[row_filter, column] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing HDI values for Nauru and Somalia and impute North Korea with median value\n",
    "replace_cell(df_covid_cleaned, df_covid_cleaned['location'] == 'Nauru', 'human_development_index', 0.692)\n",
    "replace_cell(df_covid_cleaned, df_covid_cleaned['location'] == 'Somalia', 'human_development_index', 0.385)\n",
    "fill_na_with_median(df_covid_cleaned, \"human_development_index\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_cases\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_deaths\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_cases_per_million\")\n",
    "fill_na_with_median(df_covid_cleaned, \"total_deaths_per_million\")\n",
    "fill_na_with_median(df_covid_cleaned, \"life_expectancy\")\n",
    "df_covid_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "df_covid_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the DataFrame\n",
    "df_covid_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hypotese 1: Higher population size is associated with higher total COVID-19 deaths, but not necessarily with higher deaths per capita. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4.1 Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hypotese 2: Countries with a higher Human Development Index (HDI) have experienced lower COVID-19 death rates per capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to investigate this hypothesis because HDI reflects key aspects of a country’s development, such as healthcare quality, education, and living standards.\n",
    "It seems reasonable to assume that countries with higher HDI might be better equipped to handle a health crisis like COVID-19, potentially resulting in lower death rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.1 Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we explored the new cleaned dataframe a bit, we can see that the df_covid_cleaned dataframe contains a more manageable number of columns and rows vs the original dataframe. The columns we have retained are relevant for our analysis, and we have removed unnecessary or redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.1 Check for outliers in the df_covid_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in exploring the data is checking for outlier values that are unusually high or low compared to the rest of the data.\n",
    "\n",
    "We use the IQR (Interquartile Range) method, which is a common way to detect outliers:\n",
    "\n",
    "-  First, we calculate the first quartile (Q1) and third quartile (Q3) for each selected column.\n",
    "- The IQR is the difference between Q3 and Q1.\n",
    "- Any value that falls below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR is considered an outlier.\n",
    "\n",
    "We apply this method to the two important features regarding our hypotheses: total_deaths_per_million and human_development_index. This helps us find any unusual data points that could affect the results of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in the df_covid_cleaned dataframe using IQR method\n",
    "print(\"\\n..Checking for outliers in the df_covid_cleaned dataframe:\")\n",
    "\n",
    "# Loop through selected columns\n",
    "for column in ['total_deaths_per_million', 'human_development_index']:\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = df_covid_cleaned[column].quantile(0.25)\n",
    "    Q3 = df_covid_cleaned[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "\n",
    "    # Define the lower and upper bounds for detecting outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Find rows where the value is outside the normal range\n",
    "    outliers = df_covid_cleaned[\n",
    "        (df_covid_cleaned[column] < lower_bound) | \n",
    "        (df_covid_cleaned[column] > upper_bound)\n",
    "    ]\n",
    "\n",
    "    # Print the number of outliers found for the column\n",
    "    print(f\"  {column}: {len(outliers)} outliers detected\")\n",
    "    print(outliers[['location', column]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 Conclusion of outliers: \n",
    " There are detected 7 outliers in feature 'total_deaths_per_million' with countries there has very high death toll pr million compared to the other countries. It can have an effect on average and visualizations. \n",
    "\n",
    " These outliers are likely not errors but reflect extreme yet valid data points related to the real impact of COVID-19 in certain countries. For this reason, we’ve chosen to keep them. Its possible that these values could provide valuable insights into how HDI may have had an impact on death rates per capita. Removing them might hide important patterns in the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3 Visualize the impact of HDI on Covid-19 death rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3.1 Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore whether a relationship exists between Human Development Index (HDI) and COVID-19 death rates per million, we use a scatterplot to visualize the distribution and potential correlation between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_covid_cleaned, x='human_development_index', y='total_deaths_per_million')\n",
    "plt.title('Human Development Index vs Total Deaths per Million')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above scatterplot shows no clear negative correlation between HDI and COVID-19 death rates. High HDI countries vary widely in death rates, suggesting that HDI alone does not explain the differences. Other factors likely play a role.\n",
    "\n",
    "Countries with low HDI values do not consistently show higher death rates either, reinforcing that HDI alone is not a strong predictor of COVID-19 mortality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3.2 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_covid_cleaned[['human_development_index', 'total_deaths_per_million']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix above shows a moderate positive correlation (0.47) between Human Development Index and COVID-19 death rates per million. This is surprising, as our hypothesis expected a negative correlation — that higher HDI would be linked to lower death rates. The result suggests that, in this dataset, countries with higher HDI tend to report higher death rates per million. This indicates that HDI alone does not explain the differences, and other factors likely influence the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1 Linear regression (Supervised Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate the relationship between Human Development Index (HDI) and COVID-19 death rates per million, we apply linear regression. This method helps assess the strength and direction of the relationship between these two variables and allows us to evaluate whether HDI can be used to predict COVID-19 mortality rates across countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dependent and independent variables\n",
    "\n",
    "# independent\n",
    "X = df_covid_cleaned[['human_development_index']]\n",
    "\n",
    "# dependent\n",
    "y = df_covid_cleaned[['total_deaths_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the subsets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Linear Regression model\n",
    "myreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it to our data\n",
    "myreg.fit(X_train, y_train)\n",
    "myreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the calculated coefficients\n",
    "a = myreg.coef_\n",
    "b = myreg.intercept_\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The model is a line, y = a * x + b, or y = {a} * x + {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = myreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the Linear Regression \n",
    "plt.title('Linear Regression: HDI vs COVID-19 Deaths per Million')\n",
    "plt.scatter(X, y, color='green')\n",
    "plt.plot(X_train, a*X_train + b, color='blue')\n",
    "plt.plot(X_test, y_predicted, color='orange')\n",
    "plt.xlabel('HDI')\n",
    "plt.ylabel('Deaths per Million')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph visualizes the relationship between HDI and COVID-19 deaths per million using a linear regression model. Each green dot represents a country. The orange line shows the model’s predicted trend based on the data. While there appears to be a slight upward trend, the data points are spread out, especially at higher HDI values, suggesting that the relationship might not be very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict deaths pr million from HDI\n",
    "hdi_value = 0.85\n",
    "prediction= myreg.predict([[hdi_value]])\n",
    "print(f\"Predicted death rate for HDI {hdi_value}:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_prediction = a * hdi_value + b\n",
    "print(\"Manual prediction:\", manual_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (MAE) is the mean of the absolute value of the errors\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_predicted))\n",
    "\n",
    "# Mean Squared Error (MSE) is the mean of the squared errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_predicted))\n",
    "\n",
    "# Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_predicted)))\n",
    "\n",
    "# R-squared: the proportion of the variation in the dependent variable that is predictable from the independent variable(s)\n",
    "print(\"R² score:\", r2_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1.1 Conclusion of linear regression\n",
    "Based on the results, the linear regression model dos not perform well.\n",
    "The average error (MAE) is 774 and the root mean square error (RMSE) is over 1000, which means the predictions are far from the actual values.\n",
    "The R² score is only 0.28, meaning that HDI explains just 28% of the differences in death rates between countries.\n",
    "This suggests that HDI alone is not a good predictor of COVID-19 mortality, and that other factors likely play a more important role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.3 Additional Analysis - Nordic Comparison: HDI and Death Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our earlier results showed that HDI alone does not explain differences in COVID-19 death rates, we chose to examine the Nordic countries. These countries have very similar HDI levels and welfare systems, which makes them ideal for a focused comparison. This analysis helps test whether HDI has a consistent effect within a more uniform group and can either support or weaken our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for Nordic countries\n",
    "nordic_countries = ['Denmark', 'Sweden', 'Norway', 'Finland', 'Iceland']\n",
    "df_nordic = df_covid_cleaned[df_covid_cleaned['location'].isin(nordic_countries)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns \n",
    "df_nordic_subset = df_nordic[['location', 'human_development_index', 'total_deaths_per_million']]\n",
    "df_nordic_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1 Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the death rates using a bar chart\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_nordic_subset, x='location', y='total_deaths_per_million')\n",
    "plt.title('COVID-19 Deaths per Million – Nordic Countries')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Deaths per Million')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2 Conclusion of Nordic comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite similar HDI levels among the Nordic countries, there is a clear variation in COVID-19 death rates per million. Sweden shows the highest rate, while Iceland has the lowest. This indicates that even within a region with high and comparable development, other factors beyond HDI may strongly influence COVID-19 mortality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5.4 Conclusion of Hypothesis 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis does not support the hypothesis that countries with a higher Human Development Index (HDI) have experienced lower COVID-19 death rates per capita. Although HDI was expected to be a strong predictor, the results show only a weak to moderate positive correlation (0.47), and the linear regression model performed poorly (R² = 0.28). Additionally, the Nordic comparison showed large differences in death rates despite very similar HDI values. This suggests that HDI alone is not sufficient to explain COVID-19 mortality differences, and that other factors likely play a more significant role.\n",
    "\n",
    "Although HDI reflects general development such as healthcare, education, and living standards, it may not capture specific pandemic-related factors like healthcare system capacity or testing infrastructure. Therefore, HDI alone may not be sufficient to explain variations in COVID-19 death rates, and other, more direct factors likely play a greater role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hypotese 3: Countries with a higher life expectancy and older populations (e.g. higher median age, % aged 65+, etc.) have experienced higher COVID-19 death rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6.1 Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Hypotese 4: Countries with higher prevalence of chronic health conditions (e.g. cardiovascular death rate, diabetes, smoking) have higher COVID-19 death rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to investigate this hypothesis because chronic conditions like heart disease, diabetes, and smoking are known to increase the risk of severe COVID-19 outcomes. Our goal is to examine if countries with higher rates of these conditions also experienced higher COVID-19 death rates.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.1 Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we explored the new cleaned dataframe a bit, we can see that the df_health_cleaned dataframe contains a more manageable number of columns and rows vs the original dataframe. The columns we have retained are relevant for our analysis, and we have removed unnecessary or redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.1 Check for outliers in the df_health_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in exploring the data is checking for outlier values that are unusually high or low compared to the rest of the data.\n",
    "We use the IQR (Interquartile Range) method, which is a common way to detect outliers.\n",
    "\n",
    "We apply this method to the five important features regarding our hypotheses: \n",
    "- cardiovasc_death_rate\n",
    "- diabetes_prevalence\n",
    "- female_smokers\n",
    "- male_smokers\n",
    "- total_deaths_per_million\n",
    "\n",
    "This helps us find any unusual data points that could affect the results of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in the df_health_cleaned dataframe using IQR method\n",
    "print(\"\\n..Checking for outliers in the df_health_cleaned dataframe:\")\n",
    "\n",
    "# Loop through selected columns\n",
    "for column in ['cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers', 'total_deaths_per_million']:\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "    Q1 = df_health_cleaned[column].quantile(0.25)\n",
    "    Q3 = df_health_cleaned[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "\n",
    "    # Define the lower and upper bounds for detecting outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Find rows where the value is outside the normal range\n",
    "    outliers = df_health_cleaned[\n",
    "        (df_health_cleaned[column] < lower_bound) | \n",
    "        (df_health_cleaned[column] > upper_bound)\n",
    "    ]\n",
    "\n",
    "    # Print the number of outliers found for the column\n",
    "    print(f\"  {column}: {len(outliers)} outliers detected\")\n",
    "    print(outliers[['location', column]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.2 Conclusion of outliers: \n",
    "We identified several outliers, especially in diabetes_prevalence (7 outliers). Although these values can affect averages and visualizations, we chose to keep them because they likely reflect real-world differences between countries. Removing them could hide important patterns in how chronic health conditions relate to COVID-19 death rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3 Visualize the correlation between health conditions and Covid-19 death rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3.1 Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a scatterplot to visualize how each health condition is associated with COVID-19 death rates across countries. It helps reveal any visible patterns or trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "sns.scatterplot(data=df_health_cleaned, x='cardiovasc_death_rate', y='total_deaths_per_million', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Cardiovascular Death Rate vs COVID-19 Deaths per Million')\n",
    "\n",
    "sns.scatterplot(data=df_health_cleaned, x='diabetes_prevalence', y='total_deaths_per_million', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Diabetes Prevalence vs COVID-19 Deaths per Million')\n",
    "\n",
    "sns.scatterplot(data=df_health_cleaned, x='female_smokers', y='total_deaths_per_million', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Female Smokers vs COVID-19 Deaths per Million')\n",
    "\n",
    "sns.scatterplot(data=df_health_cleaned, x='male_smokers', y='total_deaths_per_million', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Male Smokers vs COVID-19 Deaths per Million')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above scatterplots suggest only weak or no clear correlations between chronic health conditions and COVID-19 death rates across countries. Cardiovascular death rate and diabetes prevalence show no strong trend, as death rates remain spread across different values. Female smokers appear to have a slightly positive association with higher death rates, whereas male smokers show no clear pattern. Overall, the visualizations indicate that these individual health indicators alone may not strongly explain variations in COVID-19 mortality, and other factors likely contribute more significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1.3.2 Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a correlation matrix to examine the strength and direction of the relationships between the multiple health-related variables and COVID-19 death rates. It helps us compare all variables at once and identify potential patterns or associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_health_cleaned[['total_deaths_per_million', 'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True, cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix shows that female_smokers has the strongest positive correlation with COVID-19 death rates (0.58), while male_smokers shows a weak correlation (0.13), and cardiovascular_death_rate and diabetes_prevalence are slightly negative (-0.14 and -0.065). This suggests that none of the health conditions show a strong linear relationship with COVID-19 deaths, though female smoking stands out with a moderate correlation worth noting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The above scatterplot shows no clear negative correlation between HDI and COVID-19 death rates. High HDI countries vary widely in death rates, suggesting that HDI alone does not explain the differences. Other factors likely play a role.\n",
    "\n",
    "Countries with low HDI values do not consistently show higher death rates either, reinforcing that HDI alone is not a strong predictor of COVID-19 mortality -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.2 Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2.1 Multiple Linear regression (Supervised Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate the relationship between various health factors and COVID-19 death rates per million, we apply multiple linear regression. This approach helps us understand how strongly each factor contributes to differences in mortality rates, and whether these factors can collectively explain the variation in COVID-19 deaths across countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the features names\n",
    "feature_cols = ['cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers', 'male_smokers']\n",
    "\n",
    "# Select only the relevant predictor variables (independent) from the dataframe\n",
    "X = df_health_cleaned[feature_cols]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target variable (dependent variable) for prediction\n",
    "y = df_health_cleaned['total_deaths_per_million']\n",
    "\n",
    "# Print the first 5 values\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape of the subsets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Linear Regression model\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to our training data\n",
    "linreg.fit(X_train, y_train)\n",
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The intercept and coefficients are stored in system variables\n",
    "print('b0 =', linreg.intercept_)\n",
    "print('bi =', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the feature names with the coefficients\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_predicted = linreg.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_predicted))\n",
    "\n",
    "# Mean Squared Error (MSE) \n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_predicted))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_predicted)))\n",
    "\n",
    "# R-squared\n",
    "print(\"R² score:\", r2_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure how well the model explains the variation in the data (1 = perfect prediction)\n",
    "eV = round(sm.explained_variance_score(y_test, y_predicted), 2)\n",
    "print('Explained variance score ',eV )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression results\n",
    "plt.title('Multiple Linear Regression')\n",
    "plt.scatter(y_test, y_predicted, color='green', label='Predicted vs Actual')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The green dots represent individual countries, where the x-axis shows the actual COVID-19 death rates and the y-axis shows the predicted rates from the model. The red dashed line indicates perfect predictions. Since many green dots are far from the line, especially at higher values, it shows that the model struggles to accurately predict the death rates based on the health variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1.1 Conclusion of multiple linear regression\n",
    "\n",
    "<!-- Based on the results, the linear regression model dos not perform well.\n",
    "The average error (MAE) is 774 and the root mean square error (RMSE) is over 1000, which means the predictions are far from the actual values.\n",
    "The R² score is only 0.28, meaning that HDI explains just 28% of the differences in death rates between countries.\n",
    "This suggests that HDI alone is not a good predictor of COVID-19 mortality, and that other factors likely play a more important role. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiple linear regression model gave an R² score of 0.41, meaning it explains only 41% of the variation in COVID-19 death rates. The RMSE was 929 and MAE was 781, showing that the predicted values differ quite a lot from the actual ones. This suggests that the selected health factors (like diabetes and smoking) are not strong predictors on their own. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 7.3 Conclusion of Hypothesis 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show only a weak relationship between the health conditions and COVID-19 death rates. The regression model explained just 41% of the variation (R² = 0.41), and the prediction errors (MAE = 781, RMSE = 929) were high. Only female smoking showed a moderate positive correlation.\n",
    "\n",
    "Although research shows that chronic conditions increase the individual risk of severe illness or death from COVID-19, our hypothesis looked at country-level death rates. At the national level, many other factors — such as healthcare access, vaccination rates, and data reporting — likely affect the overall death rates. This may explain why our model only showed a weak relationship. Therefore, the hypothesis is only partially supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Summary and Conclusion of the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
